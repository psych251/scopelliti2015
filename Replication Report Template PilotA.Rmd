---
title: "Replication of You call it 'Self-Exhuberance'; I call it 'Bragging': Miscalibrated Prediction of Emotional Responses to Self-Promotion (Study 2) by Scopelliti, Loewenstein, Vosgerau (2015, *Psychological Science*)"
author: "Replicated by Jaclyn Schwartz; contact: jschwar2@stanford.edu"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

##Introduction

Scopelliti et al., 2015 explored how self-promotion (i.e., communicating one’s positive traits) can lead to contradicting emotional perspectives. The self-promoter may perceive that the recipient feels more positive emotions and less negative emotions about the promoter’s behavior than the recipient’s true emotional reaction. These "failures of emotional perspective taking" can have negative consequences, where recipients may see the self-promoters as bragging. The authors argued that "people tend to underestimate differences between their own and others' emotional reactions" by using their own emotions as "anchors to estimate" their recipient's emotions. They hypothesized that "self-promoters will overestimate the extent to which their behavior elicits positive emotional reactions in others, and underestimate the extent to which their behavior elicits negative emotional reactions."  

##Methods

###Power Analysis

I used G*Power 3.1 to conduct my a priori power analysis to plan the sample size. Specifically, I used a repeated-measures ANOVA for the main within-between (emotion x condition) interaction to plan my sample size since the authors used a 2-way mixed ANOVA, with 2 (between) groups and 7 (within) measurements to calculate their effects. The authors' reported effect size was $\eta_{p}^{2}$ = .07, which corresponds to effect size of f = 0.274. I set $\alpha$ = .05. In order to achieve 80% power, the yielded sample size was very small (N=16) either because the authors over-powered their sample number or the analysis yielded a huge effect. Therefore, I set the power to = .95 to increase the proposed sample size. Thus, my determined sample size is 50 to achieve 95% power. 

![G*power screenshot to determine sample size](PwrAnalysis.png)

###Planned Sample

We are planning to recruit 50 (25 per condition) workers based on the power analysis. The authors "restricted participation to respondents who were located in the United States and had not participated in Experiment 1." We will therefore restrict participation to those located in the United States. Experiment 2 is the only study from the paper undergoing replication at this time, so the "previous participation" preselection rule does not apply. 

###Materials

All materials were accessed through OSF (https://osf.io/evikb/). Participants completed *one* of the two surveys depending on random condition assignment. One survey (self-promotion) asks, “Can you describe a situation in which you have bragged to someone else about something? Please be as detailed as possible.” There is then a series of 7 "discrete emotions" (pride, happiness, annoyance, feeling inferior, jealousy, upset, anger), in which participants are asked, “how you think the person you bragged to has felt in that situation” on a scale from 1 – 7 (*1=not at all to 7=very much*). The other survey (recipient-of-self-promotion) asks, “Can you describe a situation in which someone has bragged to you about something? Please be as detailed as possible.” There is then a series of the same 7 "discrete emotions" , in which participants are asked to rate “how you felt in the situation you just described” on a scale from 1 – 7 (*1=not at all to 7=very much*).

###Procedure	

Participants completed a short survey on Amazon Mechanical Turk (MTurk). Participants were randomly assigned to one of two conditions: the self-promotion condition or the recipient-of-self-promotion condition. "Sample size was set to a minimum of 75 participants per condition, and the data were analyzed only after data collection had been completed. 154 Amazon Mechanical Turk workers accessed and completed a short study on personality and received $0.50 as compensation. As in Experiment 1, participants described an instance of having engaged in self-promotion or having been the recipient of someone else's self-promotion. Next, participants in the self-promotion condition were asked to indicate the extent to which their counterpart had felt happy for, proud of, annoyed by, jealous of, angry at, upset by, and inferior to them, whereas participants in the recipient-of-self-promotion condition were asked to rate their own level of these experienced feelings." The between-subjects factor is "reporter" (either self-promoter **or** recipient). The emotions are considered a within-subjects factor only because participants in both conditions rate the same emotions. See Table 5 from paper. "All emotions were rated on 7-point scales from *not at all* (1) to *very much* (7)." The replication will instead recruit 25 participants per condition based on the power analysis, and pilot data has been collected and analyzed. My pilot data suggest that the survey takes approximately 4-5 minutes to complete, so participants will receive 60 cents as compensation.

![Table 5. Results of Experiment 2 showing the factors of this mixed-design](Table5.png)

###Analysis Plan

This experiment is a two-cell between-subjects design where participants are randomized to *either* the self-promoter or recipient-of-self-promotion conditions (between-subjects). The authors performed a 2-way mixed ANOVA on ratings of the 7 emotional reactions. The *between-subjects* factor is condition (SP vs. R of SP), and the *within-subjects* factor is emotion. Post-hoc F-tests were performed to examine which emotions were over- or under-estimated. The topics of self-promotion (i.e., the descriptions of bragging) are categorized by 2 research assistants (RAs) only to be included as covariates. The 2 RAs independently categorized the descriptions into predefined categories of (a) achievements; (b) individual traits and skills; (c) money, possessions, power, and status; (d) family and relationships; and (e) luck. These covariates are dummy coded, and "luck serves as the baseline topic." Data will be excluded if participants claimed to have never bragged or if the situation described is not clearly bragging as defined by the coders. Demographic variables of gender and age seem to only be reported as sample descriptives in the original article, so this replication will follow that strategy.

**Key analysis of interest: A 2-way mixed ANOVA on ratings of the 7 emotional reactions, where emotion is the within-subjects factor, and condition is the between-subjects factor.**  If the interaction is significant, I will conduct post-hoc F tests to examine which emotions are over- or under-estimated.

###Differences from Original Study

Differences include planned sample size and possibly the implementation. The paper doesn't specify if the surveys were created on MTurk or through another medium, such as Qualtrics. My implementation will use MTurk to deliver the Qualtrics survey, which may be a slightly different implementation than the original study. I don't anticipate these differences to make a difference based on the large effect from the original study and the materials being presented almost exactly as is described in the original paper.

<!-- ### Methods Addendum (Post Data Collection) (comment this section out) -->

<!-- You can comment this section out prior to final report with data collection. -->

<!-- #### Actual Sample -->
<!--   Sample size, demographics, data exclusions based on rules spelled out in analysis plan -->

<!-- #### Differences from pre-data collection methods plan -->
<!--   Any differences from what was described as the original plan, or “none”. -->


##Results

The main statistic the authors report is the condition x emotion interaction, *F*(6,912)=10.90, *p*<.001, $\eta_{p}^{2}$ = .07. The main aim of the replication is to replicate this interaction. If significant, I will aim to replicate the post-hoc difference in means for each emotion to show that people in the self-promotion condition overestimated the extent to which recipients felt happy for them (*M*=4.88, *SD*=1.78, vs. *M*=3.70, *SD*=1.91), *F*(1,145)=10.85, *p*=.001, $\eta_{p}^{2}$ = .07, and proud of them (*M*=4.33, *SD*=1.81, vs. *M*=3.08, *SD*=1.77), *F*(1,145)=12.12, *p*<.001, $\eta_{p}^{2}$ = .08, and also underestimated the extent to which recipients felt annoyed (*M*=3.54, *SD*=1.94, vs. *M*=4.82, *SD*=2.15), *F*(1,145)=11.56, *p*=.001, $\eta_{p}^{2}$ = .07.

###Data preparation

Data preparation following the analysis plan. Here is the link to the replication Qualtrics survey: https://stanforduniversity.qualtrics.com/jfe/form/SV_4O72UJKN7nEkE73

	
```{r include=F}
###Data Preparation
####Load Relevant Libraries and Functions
library(lme4)
library(nlme)
library(reshape2)
library(ggplot2)
library(Matrix)
library(base)
library(lmerTest)
library(psych)
library(car)
library(effects)
library(lm.beta)
library(tidyverse)
library(ggthemes) 
library(ez)
library(broom)
library(knitr)
knitr::opts_chunk$set(error = TRUE)
####Import data: Reading in csv from Qualtrics
PilotQ <- read_csv("Scopelliti2015_November 15, 2017_18.54.csv")
head(PilotQ)
####Data exclusion / filtering
#####Deleting row 2 bc not informative
PilotQ <- PilotQ[-(1:2), ]
#####Keeping only necessary Columns (selecting only the participant ID, Input condition, and Answer items)
PilotQ <- PilotQ %>%
  select(ResponseId, starts_with("Duration"), Gender, Age, Condition.RSP.desc, Cond_RSP_happy, Cond_RSP_proud, Cond_RSP_angry, Cond_RSP_annoyed, Cond_RSP_inferior, Cond_RSP_jealous, Cond_RSP_upset, Condition.SP.desc, Cond_SP_happy, Cond_SP_proud, Cond_SP_angry, Cond_SP_annoyed, Cond_SP_inferior, Cond_SP_jealous, Cond_SP_upset) 
#####Adding Covariate columns (a) achievements; (b) individual traits and skills; (c) money, possessions, power, and status; (d) family and relationships; and (e) luck. 
PilotQ$ach_dummy <- c(0, 1, 0, 1)
PilotQ$ind_skill_dummy <- c(0, 0, 0, 0)
PilotQ$poss_money_status_power_dummy <- c(0, 0, 1, 0)
PilotQ$fam_rel_dummy <- c(1, 0, 0, 0)
PilotQ$luck_dummy <- c(0, 0, 0, 0)
#####Renaming my variables
PilotQ <- PilotQ %>%
  rename(happy_RSP = Cond_RSP_happy) %>%
  rename(proud_RSP = Cond_RSP_proud) %>%
  rename(angry_RSP = Cond_RSP_angry) %>%
  rename(annoyed_RSP = Cond_RSP_annoyed) %>%
  rename(inferior_RSP = Cond_RSP_inferior) %>%
  rename(jealous_RSP = Cond_RSP_jealous) %>%
  rename(upset_RSP = Cond_RSP_upset) %>%
  rename(happy_SP = Cond_SP_happy) %>%
  rename(proud_SP = Cond_SP_proud) %>%
  rename(angry_SP = Cond_SP_angry) %>%
  rename(annoyed_SP = Cond_SP_annoyed) %>%
  rename(inferior_SP = Cond_SP_inferior) %>%
  rename(jealous_SP = Cond_SP_jealous) %>%
  rename(upset_SP = Cond_SP_upset) 
####Prepare data for analysis - create columns etc.
PilotQ_long <- PilotQ %>%
  gather(Emotion, Rating, 
        happy_SP, proud_SP, angry_SP, annoyed_SP, inferior_SP, jealous_SP, upset_SP, 
        happy_RSP, proud_RSP, angry_RSP, annoyed_RSP, inferior_RSP, jealous_RSP, upset_RSP) %>%
  separate(Emotion, c("Emo", "Cond"), "_") 
PilotQ_long <- gather(PilotQ_long, condition , description, Condition.RSP.desc, Condition.SP.desc)
PilotQ_long
PilotQ_long <- PilotQ_long[order(PilotQ_long$ResponseId),]
PilotQ_long <- PilotQ_long %>%
  filter(!is.na(description))
PilotQ_long <- PilotQ_long %>%
  filter(!is.na(Rating))
head(PilotQ_long)
#####Making sure variables are set to correct data class
######Converting rating, my DV, to numeric data class
PilotQ_long$Rating <- as.numeric(PilotQ_long$Rating)
######Converting Id, discrete emotions, condition, and covariates into factors
PilotQ_long$ResponseId <- as.factor(PilotQ_long$ResponseId)
PilotQ_long$Emo <- as.factor(PilotQ_long$Emo)
PilotQ_long$Cond <- as.factor(PilotQ_long$Cond)
PilotQ_long$ach_dummy <- as.factor(PilotQ_long$ach_dummy)
contrasts(PilotQ_long$ach_dummy) = c(0,1)
PilotQ_long$ind_skill_dummy <- as.factor(PilotQ_long$ind_skill_dummy)
######contrasts(PilotQ_long$ind_skill_dummy) = c(0,1)
###### Since contrasts can only be applied to factors with 2 or more levels and no subject endorsed this category "ind_skill_dummy", this covariate will be left out for now
PilotQ_long$poss_money_status_power_dummy <- as.factor(PilotQ_long$poss_money_status_power_dummy)
contrasts(PilotQ_long$poss_money_status_power_dummy) = c(0,1)
PilotQ_long$fam_rel_dummy <- as.factor(PilotQ_long$fam_rel_dummy)
contrasts(PilotQ_long$fam_rel_dummy) = c(0,1)
PilotQ_long$luck_dummy <- as.factor(PilotQ_long$luck_dummy)
###### contrasts(PilotQ_long$luck_dummy) = c(0,1)
###### Since contrasts can only be applied to factors with 2 or more levels and no subject endorsed this category "luck_dummy", this covariate will be left out for now
```

### Confirmatory analysis

#### Descriptives
```{r}
Npart <- length(PilotQ$ResponseId) # 4
PilotQ$Age <- as.numeric(PilotQ$Age)
mean_age <- mean(PilotQ$Age) # 27
sd_age <- sd(PilotQ$Age) # 1.825742
sd_age_r <- round(sd_age, digits = 2) 
PilotQ$Gender <- as.factor(PilotQ$Gender)
Nmale <- PilotQ[which(PilotQ$Gender == '1'), ]
Nfemale <- PilotQ[which(PilotQ$Gender == '2'), ]          
percent_female <- (3/4)*100 # 75%
percent_male <- (1/4)*100 # 25% 
```
`r Npart` participants (mean age = `r mean_age` years, *SD* = `r sd_age_r`; `r percent_male`% male, `r percent_female`% female) accessed and completed a short study on personality.

#### 2-way mixed ANOVA
```{r}
# With Covariates (The Between-subjects factor was estimated with inclusion of the topic covariates)
Cond_aov <- aov(Rating~ (Cond) + ach_dummy + poss_money_status_power_dummy + fam_rel_dummy + Error(ResponseId/(Emo)), data = PilotQ_long)
Cond_aov_sum <- summary(Cond_aov)
print(Cond_aov_sum)
# Without Covariates (The Within-subjects factor estimated without inclusion of the topic covariates)
Emo_aov_noCov <- aov(Rating~ (Emo) + Error(ResponseId/(Emo)), data = PilotQ_long)
Emo_aov_noCov_sum <- summary(Emo_aov_noCov)
print(Emo_aov_noCov_sum)
# With Covariates (The interaction was estimated with topic covariates)
mainInt <- aov(Rating~ (Cond*Emo) + ach_dummy + poss_money_status_power_dummy + fam_rel_dummy + Error(ResponseId/(Emo)), data = PilotQ_long)
mainInt_sum <- summary(mainInt)
knitr::kable(broom::tidy(mainInt))
```

```{r, include=FALSE}
# Saved parameters for the Condition main effect
Cond_Fstat <- Cond_aov_sum[[1]][[1]][[1,"F value"]] # 0.125
Cond_Fstat_r <- round(Cond_Fstat, digits = 2) # 0.12
Cond_pval <- Cond_aov_sum[[1]][[1]][[1,"Pr(>F)"]] # 0.7836531
Cond_pval_r <- round(Cond_pval, digits = 3) # 0.784
Cond_num_df <- Cond_aov_sum[[1]][[1]][[1, "Df"]] # 1
Cond_den_df <- Cond_aov_sum[[1]][[1]][[3, "Df"]] # 1

# Saved parameters for the Emotion main effect
Emo_Fstat <- Emo_aov_noCov_sum[[2]][[1]][[1,"F value"]] # 3.198347
Emo_Fstat_r <- round(Emo_Fstat, digits = 2) # 3.2
Emo_pval <- Emo_aov_noCov_sum[[2]][[1]][[1,"Pr(>F)"]] # 0.02568918
Emo_pval_r <- round(Emo_pval, digits = 3) # 0.026
Emo_num_df <- Emo_aov_noCov_sum[[2]][[1]][[1, "Df"]] # 6
Emo_den_df <- Emo_aov_noCov_sum[[2]][[1]][[2, "Df"]] # 18

# Saved parameters for the interaction
Fstat <- mainInt_sum[[2]][[1]][[2,"F value"]] # 1.61194
Fstat_r <- round(Fstat, digits = 2) # 1.612
pval <- mainInt_sum[[2]][[1]][[2,"Pr(>F)"]] # 0.2265528
pval_r <- round(pval, digits = 3) # 0.227
num_df <- mainInt_sum[[2]][[1]][[2, "Df"]] # 6
den_df <- mainInt_sum[[2]][[1]][[3, "Df"]] # 12

# Calculating partial eta squared
SSn <- mainInt_sum[[2]][[1]][[2,"Sum Sq"]] # 15.42857
SSd <- mainInt_sum[[2]][[1]][[3,"Sum Sq"]] # 19.14286
part_eta <- SSn/(SSn + SSd) # 0.446281
part_eta_r <- round(part_eta, digits = 2) # 0.45
```

As per the authors' analyses, I estimated the main effect of *Condition* with the inclusion of topic covariates, I estimated the main effect of *Emotion* without topic covariates, and I estimated the interaction with the inclusion of topic covariates. There is a main effect of *Emotion*, *F*(`r Emo_num_df`,`r Emo_den_df`) = `r Emo_Fstat_r`, *p* = `r Emo_pval_r` but no main effect of *Condition*, *F*(`r Cond_num_df`,`r Cond_den_df`) = `r Cond_Fstat_r`, *p* = `r Cond_pval_r`, which is consistent with the authors' findings. However, the interaction statistic that I aimed to replicate is not significant, *F*(`r num_df`,`r den_df`) = `r Fstat_r`, *p* = `r pval_r`, $\eta_{p}^{2}$ = `r part_eta_r`. I therefore did not conduct post-hoc tests since the interaction wasn't significant, which will impact the interpretation of any simple effects. I did not include age or gender in my models because the original paper does not do so.

#### Graphing the interaction
```{r, include=FALSE}
# Bargraph with SE bars
meanAndSem=function(x) c(mn = mean(x,na.rm=TRUE), se = sd(x,na.rm=T)/sqrt((sum(as.double(!is.na(x))))), len=sum(as.double(!is.na(x))))
require(plyr)
require(reshape)
Fig1 = ddply(PilotQ_long, .(Cond,Emo), summarize,mn = meanAndSem(Rating)[1], se = meanAndSem(Rating)[2])
Fig1
limits = aes(ymax = mn + se, ymin=mn - se)
```

```{r}
Fig1_plot = ggplot(Fig1, aes(x = factor(Emo), y = mn, fill = factor(Cond)))+geom_bar(width=.9, stat = 'identity', position=position_dodge(.95),size=1.5,alpha = 0.7)+labs(title = "Miscalibrated Predictions of Responses to Self-Promotion", y="Extent of Emotion",x="Emotion")+geom_errorbar(limits,color = 'black',position=position_dodge(.95),width=0.25) + labs(color = "Group") + theme(axis.title=element_text(face="bold",size="14", color="black")) + theme(title = element_text(face = "bold")) +  scale_fill_discrete("Group", labels = c("Experienced by Recipient", "Predicted by Self-Promoter"))
print(Fig1_plot)
```

![Fig.2 from orginal paper (Scopelliti et al., 2015)](Fig.2_Scopelliti2015.png)
This replication graph and the screenshot of the original graph (Fig. 2) shows self-Promoters' predictions of recipients' experienced emotions and recipients' ratings of their actual experienced emotions. I do re-create this graph as well from the authors' data below when I check my statistical tests on their data to ensure it looks the same as what is reported. Error bars represent +/-1 SEM. For the replication graph, some of the error bars are huge due to the low N of this pilot. Overall, however, the replicated visualization is difficult to interpret given the non-significant interaction of emotion and condition and the low N of this pilot.

####Testing my ANOVA models and Graphing the interaction from Original Data 
```{r, include=FALSE}
library(readxl)
study2 <- read_excel("study 2.xlsx", sheet = 1)
head(study2) # 0 = RSP, 1 = SP
```

#####Data Preparation
```{r, include=FALSE}
# Data Preparation
study2_long <- study2 %>%
  gather(Emotion, Rating, 
        happy, proud, angry, annoyed, inferior, jealous, upset) 
study2_long <- study2_long[order(study2_long$subj),]
head(study2_long)
study2_long$Rating <- as.numeric(study2_long$Rating)
######Converting Id, discrete emotions, condition, and covariates into factors
study2_long$subj <- as.factor(study2_long$subj)
study2_long$Emotion <- as.factor(study2_long$Emotion)
study2_long$reporter <- as.factor(study2_long$reporter)
contrasts(study2_long$reporter) = c(0,1)
study2_long$ach_dummy <- as.factor(study2_long$ach_dummy)
study2_long$ind_skill_d <- as.factor(study2_long$ind_skill_d)
study2_long$poss_money_status_power_dummy <- as.factor(study2_long$poss_money_status_power_dummy)
study2_long$fam_rel_dummy <- as.factor(study2_long$fam_rel_dummy)
study2_long$luck_dummy <- as.factor(study2_long$luck_dummy)
```

```{r, include=FALSE}
# Bargraph with SE bars
meanAndSem=function(x) c(mn = mean(x,na.rm=TRUE), se = sd(x,na.rm=T)/sqrt((sum(as.double(!is.na(x))))), len=sum(as.double(!is.na(x))))
require(plyr)
require(reshape)
Fig1_Orignal = ddply(study2_long, .(reporter,Emotion), summarize,mn = meanAndSem(Rating)[1], se = meanAndSem(Rating)[2])
Fig1_Orignal
limits = aes(ymax = mn + se, ymin=mn - se)
```

```{r}
Fig1_Original_plot = ggplot(Fig1_Orignal, aes(x = factor(Emotion), y = mn, fill = factor(reporter)))+geom_bar(width=.9, stat = 'identity', position=position_dodge(.95),size=1.5,alpha = 0.7)+labs(title = "Miscalibrated Predictions of Responses to Self-Promotion", y="Extent of Emotion",x="Emotion")+geom_errorbar(limits,color = 'black',position=position_dodge(.95),width=0.25) + labs(color = "Group") + theme(axis.title=element_text(face="bold",size="14", color="black")) + theme(title = element_text(face = "bold")) +  scale_fill_discrete("Group", labels = c("Experienced by Recipient", "Predicted by Self-Promoter"))
print(Fig1_Original_plot)
```

The graph recreated from the authors' data does seem to replicate.

#####Confirmatory Analysis
```{r}
# With Covariates (Between-subjects factor estimated with inclusion of the topic covariates)
Study2Cond_aov <- aov(Rating ~ (reporter) + ach_dummy + ind_skill_d + poss_money_status_power_dummy + fam_rel_dummy + luck_dummy + Error(subj/(Emotion)), data = study2_long) # 0 = RSP, 1 = SP
Study2Cond_aov_sum <- summary(Study2Cond_aov)
print(Study2Cond_aov_sum)
# Without Covariates (Within-subjects factor estimated without inclusion of the topic covariates)
Emo_aov_noCov <- aov(Rating ~ (Emotion) + Error(subj/(Emotion)), data = study2_long)
Emo_aov_noCov_sum <- summary(Emo_aov_noCov)
print(Emo_aov_noCov_sum)
# With Covariates (The interaction was estimated with topic covariates)
Study2mainInt_aov <- aov(Rating ~ (reporter*Emotion) + ach_dummy + ind_skill_d + poss_money_status_power_dummy + fam_rel_dummy + luck_dummy + Error(subj/(Emotion)), data = study2_long)
Study2mainInt_aov_sum <- summary(Study2mainInt_aov)
knitr::kable(broom::tidy(Study2mainInt_aov))
```

```{r, include=FALSE}
# Saved parameters for the Condition main effect
Cond_Fstat_study2 <- Study2Cond_aov_sum [[1]][[1]][[1,"F value"]] # 2.844642
Cond_Fstat_r_study2 <- round(Cond_Fstat_study2, digits = 2) # 2.84
Cond_pval_study2 <- Study2Cond_aov_sum[[1]][[1]][[1,"Pr(>F)"]] # 0.09384429
Cond_pval_r_study2 <- round(Cond_pval_study2, digits = 3) # 0.094
Cond_num_df_study2 <- Study2Cond_aov_sum[[1]][[1]][[1, "Df"]] # 1
Cond_den_df_study2 <- Study2Cond_aov_sum[[1]][[1]][[3, "Df"]] # 1

# Saved parameters for the Emotion main effect
Emo_Fstat_study2  <- Emo_aov_noCov_sum[[2]][[1]][[1,"F value"]] # 20.43889
Emo_Fstat_r_study2 <- round(Emo_Fstat_study2, digits = 2) # 20.44
Emo_pval_study2 <- Emo_aov_noCov_sum[[2]][[1]][[1,"Pr(>F)"]] # 1.641914e-22
Emo_pval_r_study2 <- round(Emo_pval_study2, digits = 3) # 0
Emo_num_df_study2 <- Emo_aov_noCov_sum[[2]][[1]][[1, "Df"]] # 6
Emo_den_df_study2 <- Emo_aov_noCov_sum[[2]][[1]][[2, "Df"]] # 900

# Saved parameters for the interaction
Fstat_study2 <- Study2mainInt_aov_sum[[2]][[1]][[2,"F value"]] # 10.7547
Fstat_r_study2 <- round(Fstat_study2, digits = 2) # 10.75
pval_study2 <- Study2mainInt_aov_sum[[2]][[1]][[2,"Pr(>F)"]] # 1.432555e-11
pval_r_study2  <- round(pval_study2, digits = 3) # 0
num_df_study2 <- Study2mainInt_aov_sum[[2]][[1]][[2, "Df"]] # 6
den_df_study2 <- Study2mainInt_aov_sum[[2]][[1]][[3, "Df"]] # 894

# Calculating partial eta squared
SSn_study2 <- Study2mainInt_aov_sum[[2]][[1]][[2,"Sum Sq"]] # 199.4427
SSd_study2 <- Study2mainInt_aov_sum[[2]][[1]][[3,"Sum Sq"]] # 2763.161
part_eta_study2 <- SSn_study2/(SSn_study2 + SSd_study2) # 0.06732008
part_eta_r_study2 <- round(part_eta_study2, digits = 2) # 0.07
```

In testing my code on the authors' data, there is a main effect of *Emotion*, *F*(`r Emo_num_df_study2`,`r Emo_den_df_study2`) = `r Emo_Fstat_r_study2`, *p*<.001, but no main effect of *Condition*, *F*(`r Cond_num_df_study2`,`r Cond_den_df_study2`) = `r Cond_Fstat_r_study2`, *p* = `r Cond_pval_r_study2`. The interaction between *Emotion* and *Condition* is also significant, *F*(`r num_df_study2`,`r den_df_study2`) = `r Fstat_r_study2`, *p*<.001, $\eta_{p}^{2}$ = `r part_eta_r_study2`. These statistics do not exactly replicate the authors’ reporting, but it is very similar, and the conclusions drawn would be the same. For example, for the main interaction, the authors report F(6,912)=10.90, p<.001, partial eta = .07. However, my code to replicate yields, F(6,894)= 10.75, p<.001, partial eta = .07. So, only the F statistic and the denominator degrees of freedom are slightly off from what the authors report.

#####If gathering the covariates into long format, which I commented out
```{r, echo=FALSE}
# Data Preparation
# study2_long <- study2 %>%
#   gather(Emotion, Rating, 
#         happy, proud, angry, annoyed, inferior, jealous, upset) 
# study2_long <- study2_long %>%
#   gather(Topics , Topic_Cov,
#         ach_dummy, ind_skill_d, poss_money_status_power_dummy, fam_rel_dummy, luck_dummy) 
# study2_long <- study2_long[order(study2_long$subj),]
# head(study2_long)
# study2_long$Rating <- as.numeric(study2_long$Rating)
# study2_long$Topics <- as.factor(study2_long$Topics)
# study2_long$Topic_Cov <- as.factor(study2_long$Topic_Cov)
```

```{r, echo=FALSE}
# mainInt <- ezANOVA(study2_long,
#         dv = Rating,
#         wid = subj,
#         within = Emotion,
#         between = reporter,
#         between_covariates = (Topic_Cov),
#         detailed = T)
# print(mainInt)
# kable((mainInt), digits = 3)
# 
# mainInt_aov <- aov(Rating~ (reporter*Emotion) + Topic_Cov + Error(subj/(Emotion)), data = study2_long)
# print(summary(mainInt_aov))
# mainInt_aov_noCov <- aov(Rating ~ (reporter*Emotion) + Error(subj/(Emotion)), data = study2_long)
# print(summary(mainInt_aov_noCov))
```
The degrees of freedom are very off when gathering the topics into long format, whereas when I leave the covariates in wide format the degrees of freedom are only slightly off. Therefore, I think I will continue the analysis with the topic covariates in wide-format and my other variables in long-format.

###Exploratory analyses

If the interaction after actual data collection is significant, here is the code I would use to conduct post-hoc F tests. I am using this code on the authors' data to see if I get the same results.

```{r}
# 0 = RSP, 1 = SP
SPcond <- study2[which(study2$reporter == '1'),]
RSPcond <- study2[which(study2$reporter == '0'),]
happy <- study2_long[which(study2_long$Emotion == 'happy'),]
proud <- study2_long[which(study2_long$Emotion == 'proud'),]
annoyed <- study2_long[which(study2_long$Emotion == 'annoyed'),]
jealous <- study2_long[which(study2_long$Emotion == 'jealous'),]
upset <- study2_long[which(study2_long$Emotion == 'upset'),]
angry <- study2_long[which(study2_long$Emotion == 'angry'),]
inferior <- study2_long[which(study2_long$Emotion == 'inferior'),]

# happy
mean(SPcond$happy) # 4.875
sd(SPcond$happy) # 1.775716
mean(RSPcond$happy) # 3.696203
sd(RSPcond$happy) # 1.910527
summary(aov(Rating ~ reporter + ach_dummy + ind_skill_d + poss_money_status_power_dummy + fam_rel_dummy + luck_dummy, data = happy)) # F=15.878, p<.001
# proud
mean(SPcond$proud) # 4.333333
sd(SPcond$proud) # 1.768265
mean(RSPcond$proud) # 3.075949
sd(RSPcond$proud) # 1.81003
summary(aov(Rating ~ reporter + ach_dummy + ind_skill_d + poss_money_status_power_dummy + fam_rel_dummy + luck_dummy, data = proud)) #F=19.406, p<.001
# annoyed
mean(SPcond$annoyed) # 3.541667
sd(SPcond$annoyed) # 1.942392
mean(RSPcond$annoyed) # 4.822785
sd(RSPcond$annoyed) # 2.146909
summary(aov(Rating ~ reporter + ach_dummy + ind_skill_d + poss_money_status_power_dummy + fam_rel_dummy + luck_dummy, data = annoyed)) # F=14.544, p<.001 
# jealous
mean(SPcond$jealous) # 3.597222
sd(SPcond$jealous) # 2.066907
mean(RSPcond$jealous) # 2.822785
sd(RSPcond$jealous) # 2.011247
summary(aov(Rating ~ reporter + ach_dummy + ind_skill_d + poss_money_status_power_dummy + fam_rel_dummy + luck_dummy, data = jealous)) # F=5.526, p=0.020
# upset
mean(SPcond$upset) # 2.583333
sd(SPcond$upset) # 1.709542
mean(RSPcond$upset) # 3.037975
sd(RSPcond$upset) # 1.856679
summary(aov(Rating ~ reporter + ach_dummy + ind_skill_d + poss_money_status_power_dummy + fam_rel_dummy + luck_dummy, data = upset)) # F=2.429, p=0.121
# angry
mean(SPcond$angry) # 2.736111
sd(SPcond$angry) # 1.609768
mean(RSPcond$angry) # 2.974684
sd(RSPcond$angry) # 1.804373
summary(aov(Rating ~ reporter + ach_dummy + ind_skill_d + poss_money_status_power_dummy + fam_rel_dummy + luck_dummy, data = angry)) # F=0.743, p=0.390
# inferior
mean(SPcond$inferior) # 2.930556
sd(SPcond$inferior) # 1.689457
mean(RSPcond$inferior) # 2.43038
sd(RSPcond$inferior) # 1.823518
summary(aov(Rating ~ reporter + ach_dummy + ind_skill_d + poss_money_status_power_dummy + fam_rel_dummy + luck_dummy, data = inferior)) # F=2.985, p=0.0862 
```

The code above to replicate the means and standard deviations of the original data matches what was reported, except there are a few minor errors, which may have been typos in the paper. Only the standard deviations within *proud*, *jealous*, and *inferior* are switched between the two conditions in the paper compared to what has been yielded from the code above. For the simple effects F tests, I tested multiple models on the original data. Every function (anova on lmer, aov, ezANOVA) yields the same F statistics and p values, but the degrees of freedom differ amongst each function. When matching these statistics to those reported in the paper, the F statistics are off by a few numbers, but it doesn't change the conclusion drawn from simple effects in the paper. The aov function seems to be the closest to the degrees of freedom reported in the paper when testing this code on the authors' data, so I may continue to use that function for the main effects, interaction effect, and simple effects for the actual replication. 

## Discussion

### Summary of Replication Attempt

The pilot data fails to replicate the main interaction of *Condition* and *Emotion*, which is likely due to the low N of this pilot. However, I did replicate the significant main effect of *Emotion* and non-significant main effect of *Condition*. I would consider this a partial replication for this pilot data. Given the several different ways to conduct F tests (which is the test done in the paper), this pilot helped in deciding how to code the statistical tests for actual data collection.

### Commentary

(a) The results with pilot data are difficult to interpret given this pilot data consists of 4 participants and was only intended to test the viability and the code that I will eventually use for actual data collection. Therefore, I used the authors' data to test the exploratory code I would use to conduct post-hoc tests if the interaction ends up being significant. 

(b) Although this replication partially failed, the F statistic is in the right direction and with more people, might attain significance.

(c) One thing to note is that I coded the topics of bragging myself instead of having 2 RAs code these topics since this is the pilot. I will be having another student help me code these topics for actual data collection. I plan to use aov instead of ezANOVA because of the warning that ezANOVA "is experimental and not yet fully validated."  The aov function seems to be working well with how I formatted the data, so I may keep it that way moving forward with the replication, but any feedback on this is appreciated!

